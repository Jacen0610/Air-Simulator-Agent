# C:/workspace/python/Air-Simulator-Agent/environment.py
import grpc
import torch
from proto import simulator_pb2
from proto import simulator_pb2_grpc


class GoSimulatorEnv:
    """
    ä¸ Go æ¨¡æ‹Ÿå™¨è¿›è¡Œ gRPC é€šä¿¡çš„ Python ç¯å¢ƒã€‚
    """

    def __init__(self, host='localhost:50051'):
        """
        æ„é€ å‡½æ•°ç°åœ¨åªè´Ÿè´£å»ºç«‹è¿æ¥ï¼Œä¸è¿›è¡Œ resetã€‚
        """
        print("ğŸ”Œ æ­£åœ¨è¿æ¥åˆ° Go gRPC æœåŠ¡å™¨...")
        self.channel = grpc.insecure_channel(host)
        self.stub = simulator_pb2_grpc.SimulatorStub(self.channel)
        self.agent_ids = []  # agent_ids å°†åœ¨ç¬¬ä¸€æ¬¡ reset æ—¶è¢«è®¾ç½®
        print("âœ… è¿æ¥æˆåŠŸï¼")

    def reset(self):
        """
        é‡ç½®ç¯å¢ƒï¼Œå¼€å§‹ä¸€ä¸ªæ–°çš„ episodeã€‚
        è¿™æ˜¯è·å–æ™ºèƒ½ä½“åˆ—è¡¨å’Œåˆå§‹è§‚æµ‹çš„å”¯ä¸€å…¥å£ã€‚
        """
        try:
            request = simulator_pb2.ResetRequest()
            response = self.stub.Reset(request)

            # åœ¨ç¬¬ä¸€æ¬¡ reset æ—¶ï¼Œè®¾ç½® agent_ids
            if not self.agent_ids:
                self.agent_ids = list(response.states.keys())

            observations = {
                agent_id: self._convert_observation(state.observation)
                for agent_id, state in response.states.items()
            }
            return observations
        except grpc.RpcError as e:
            print(f"âŒ Reset gRPC è¯·æ±‚å¤±è´¥: {e.status()}")
            return None

    def step(self, actions):
        """
        åœ¨ç¯å¢ƒä¸­æ‰§è¡Œä¸€æ­¥ã€‚
        """
        # **[æ ¸å¿ƒä¿®æ­£]** ç›´æ¥å°†æ•´æ•°åŠ¨ä½œ+1èµ‹å€¼ã€‚
        # gRPCåº“ä¼šè‡ªåŠ¨å¤„ç†æ•´æ•°åˆ°æšä¸¾çš„æ˜ å°„ã€‚
        proto_actions = {
            agent_id: action + 1
            for agent_id, action in actions.items()
        }

        try:
            request = simulator_pb2.StepRequest(actions=proto_actions)
            response = self.stub.Step(request)

            observations = {
                agent_id: self._convert_observation(state.observation)
                for agent_id, state in response.states.items()
            }
            rewards = {
                agent_id: state.reward
                for agent_id, state in response.states.items()
            }
            dones = {
                agent_id: state.done
                for agent_id, state in response.states.items()
            }

            return observations, rewards, dones, {}  # è¿”å›ä¸€ä¸ªç©ºçš„ info å­—å…¸ä»¥åŒ¹é… Gym API
        except grpc.RpcError as e:
            print(f"âŒ Step gRPC è¯·æ±‚å¤±è´¥: {e.status()}")
            # åœ¨å‡ºé”™æ—¶è¿”å›ä¸€ä¸ªåˆç†çš„å€¼ï¼Œé¿å…ç¨‹åºå´©æºƒ
            return None, None, None, None

    def _convert_observation(self, obs_proto):
        """
        å°† protobuf çš„ Observation è½¬æ¢ä¸º PyTorch Tensorã€‚
        """
        # **[æ ¸å¿ƒä¿®æ”¹]** æŒ‰ç…§ .proto æ–‡ä»¶å®šä¹‰çš„é¡ºåºæ„å»º 6 ç»´å¼ é‡
        return torch.tensor([
            float(obs_proto.has_message),
            float(obs_proto.top_message_priority),
            float(obs_proto.primary_channel_busy),
            float(obs_proto.backup_channel_busy),
            float(obs_proto.pending_acks_count),  # <--- æ–°å¢
            float(obs_proto.outbound_queue_length)  # <--- æ–°å¢
        ], dtype=torch.float32)

    def close(self):
        """
        å…³é—­ gRPC è¿æ¥ã€‚
        """
        if self.channel:
            self.channel.close()
            print("ğŸ”Œ gRPC è¿æ¥å·²å…³é—­ã€‚")